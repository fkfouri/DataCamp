{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    !pip install pyspark==\"2.4.5\"  --quiet\n",
    "except:\n",
    " print(\"Running throw py file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext as sc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Estudo Spark - Query Plans - Fabio Kfouri\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de dados usando uma fonte pública"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte de Dados:\n",
    "\n",
    "https://data.humdata.org/dataset/faostat-prices-for-brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addFile('https://data.humdata.org/dataset/bdf7bcca-28ae-47c5-8993-c87a7c5c04c0/resource/c16c15f5-efaf-4950-b848-94935987d312/download/producer-prices_bra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(SparkFiles.get(\"producer-prices_bra.csv\"), header = True, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------+---------+-------------+---------------+---------------+------------+--------------------------+---------+----------+-----------+------------+---------------+--------------------+----+\n",
      "|Iso3         |StartDate  |EndDate   |Area Code|Area         |Item Code      |Item           |Element Code|Element                   |Year Code|Year      |Months Code|Months      |Unit           |Value               |Flag|\n",
      "+-------------+-----------+----------+---------+-------------+---------------+---------------+------------+--------------------------+---------+----------+-----------+------------+---------------+--------------------+----+\n",
      "|#country+code|#date+start|#date+end |null     |#country+name|#indicator+code|#indicator+name|null        |null                      |null     |#date+year|null       |null        |#indicator+type|#indicator+value+num|null|\n",
      "|BRA          |1991-01-01 |1991-12-31|21       |Brazil       |515            |Apples         |5530        |Producer Price (LCU/tonne)|1991     |1991      |7021       |Annual value|LCU            |105691.000000       |*   |\n",
      "|BRA          |1992-01-01 |1992-12-31|21       |Brazil       |515            |Apples         |5530        |Producer Price (LCU/tonne)|1992     |1992      |7021       |Annual value|LCU            |1969620.000000      |*   |\n",
      "|BRA          |1993-01-01 |1993-12-31|21       |Brazil       |515            |Apples         |5530        |Producer Price (LCU/tonne)|1993     |1993      |7021       |Annual value|LCU            |26770.000000        |*   |\n",
      "|BRA          |1994-01-01 |1994-12-31|21       |Brazil       |515            |Apples         |5530        |Producer Price (LCU/tonne)|1994     |1994      |7021       |Annual value|LCU            |258.000000          |*   |\n",
      "+-------------+-----------+----------+---------+-------------+---------------+---------------+------------+--------------------------+---------+----------+-----------+------------+---------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma Temp Table (usando registerTempTable que é parte do 1.x API e foi <i>deprecated</i> no Spark 2.0 foi substituida por <b>createOrReplaceTempView</b> e <b>createTempView</b>. Tem a mesma funcao que o createOrReplaceTempView."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='df', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.registerTempTable(\"df\")\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Explain query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = spark.sql('EXPLAIN SELECT * FROM df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                plan|\n",
      "+--------------------+\n",
      "|== Physical Plan ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(plan='== Physical Plan ==\\n*(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma facil de obter o explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Execute ExplainCommand\n",
      "   +- ExplainCommand 'Project [*], false, false, false\n"
     ]
    }
   ],
   "source": [
    "temp.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain em um Dataframe in cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Iso3: string, StartDate: string, EndDate: string, Area Code: string, Area: string, Item Code: string, Item: string, Element Code: string, Element: string, Year Code: string, Year: string, Months Code: string, Months: string, Unit: string, Value: string, Flag: string\n",
      "Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n"
     ]
    }
   ],
   "source": [
    "df.cache()\n",
    "df.explain(extended = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['count DESC NULLS LAST], true\n",
      "+- Aggregate [Item#274], [Item#274, count(1) AS count#741L]\n",
      "   +- Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Item: string, count: bigint\n",
      "Sort [count#741L DESC NULLS LAST], true\n",
      "+- Aggregate [Item#274], [Item#274, count(1) AS count#741L]\n",
      "   +- Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [count#741L DESC NULLS LAST], true\n",
      "+- Aggregate [Item#274], [Item#274, count(1) AS count#741L]\n",
      "   +- Project [Item#274]\n",
      "      +- InMemoryRelation [Iso3#268, StartDate#269, EndDate#270, Area Code#271, Area#272, Item Code#273, Item#274, Element Code#275, Element#276, Year Code#277, Year#278, Months Code#279, Months#280, Unit#281, Value#282, Flag#283], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [count#741L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(count#741L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[Item#274], functions=[count(1)], output=[Item#274, count#741L])\n",
      "      +- Exchange hashpartitioning(Item#274, 200)\n",
      "         +- *(1) HashAggregate(keys=[Item#274], functions=[partial_count(1)], output=[Item#274, count#825L])\n",
      "            +- InMemoryTableScan [Item#274]\n",
      "                  +- InMemoryRelation [Iso3#268, StartDate#269, EndDate#270, Area Code#271, Area#272, Item Code#273, Item#274, Element Code#275, Element#276, Year Code#277, Year#278, Months Code#279, Months#280, Unit#281, Value#282, Flag#283], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                        +- *(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Item')\\\n",
    "    .count()\\\n",
    "    .sort(F.desc('count'))\\\n",
    "    .explain(extended = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['count DESC NULLS LAST], true\n",
      "+- 'Aggregate ['Item], ['Item, 'count(1) AS count#906]\n",
      "   +- 'UnresolvedRelation `df`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Item: string, count: bigint\n",
      "Sort [count#906L DESC NULLS LAST], true\n",
      "+- Aggregate [Item#274], [Item#274, count(1) AS count#906L]\n",
      "   +- SubqueryAlias `df`\n",
      "      +- Relation[Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [count#906L DESC NULLS LAST], true\n",
      "+- Aggregate [Item#274], [Item#274, count(1) AS count#906L]\n",
      "   +- Project [Item#274]\n",
      "      +- InMemoryRelation [Iso3#268, StartDate#269, EndDate#270, Area Code#271, Area#272, Item Code#273, Item#274, Element Code#275, Element#276, Year Code#277, Year#278, Months Code#279, Months#280, Unit#281, Value#282, Flag#283], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [count#906L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(count#906L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[Item#274], functions=[count(1)], output=[Item#274, count#906L])\n",
      "      +- Exchange hashpartitioning(Item#274, 200)\n",
      "         +- *(1) HashAggregate(keys=[Item#274], functions=[partial_count(1)], output=[Item#274, count#992L])\n",
      "            +- InMemoryTableScan [Item#274]\n",
      "                  +- InMemoryRelation [Iso3#268, StartDate#269, EndDate#270, Area Code#271, Area#272, Item Code#273, Item#274, Element Code#275, Element#276, Year Code#277, Year#278, Months Code#279, Months#280, Unit#281, Value#282, Flag#283], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                        +- *(1) FileScan csv [Iso3#268,StartDate#269,EndDate#270,Area Code#271,Area#272,Item Code#273,Item#274,Element Code#275,Element#276,Year Code#277,Year#278,Months Code#279,Months#280,Unit#281,Value#282,Flag#283] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/fkfouri/AppData/Local/Temp/spark-e3609bcd-046b-4ed7-80a9-6ac6bed..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Iso3:string,StartDate:string,EndDate:string,Area Code:string,Area:string,Item Code:string,...\n"
     ]
    }
   ],
   "source": [
    "spark.sql(''' \n",
    "SELECT Item, count(*) as count \n",
    "FROM df\n",
    "group by Item\n",
    "Order by count desc\n",
    "''').explain(extended = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
