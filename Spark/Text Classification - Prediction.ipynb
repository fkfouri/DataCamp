{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "Este fará usando conceitos de Machine Learning uma previsão da última palavra de uma frase/setença de uma pessoa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-Y520:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Endword Prediction  - Fabio Kfouri</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22cb7e8a788>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Spark Endword Prediction  - Fabio Kfouri\")\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Project Gutenberg...|\n",
      "|                    |\n",
      "|This eBook is for...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read book\n",
    "df = spark.read.text(\"sherlock\\sherlock.txt\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+\n",
      "|word                                                                                      |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "|[project, gutenberg, s, the, adventures, of, sherlock, holmes, , by, arthur, conan, doyle]|\n",
      "|[]                                                                                        |\n",
      "|[this, ebook, is, for, the, use, of, anyone, anywhere, at, no, cost, and, with]           |\n",
      "|[almost, no, restrictions, whatsoever, , , you, may, copy, it, , give, it, away, or]      |\n",
      "|[re-use, it, under, the, terms, of, the, project, gutenberg, license, included]           |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformando em minuscula\n",
    "df1 = df.select(F.lower(F.col('value')).alias('value'))\n",
    "# Replace de termos\n",
    "df2 = df1.select(F.regexp_replace('value', 'mr\\.', 'mr').alias('value'))\n",
    "df2 = df1.select(F.regexp_replace('value', 'don\\'t', 'do not').alias('value'))\n",
    "# Tokenizando e removendo simbolos indesejados\n",
    "punctuation = \"_|.\\?\\!\\\",\\'\\[\\]\\*():;<>”“’\"\n",
    "df3 = df2.select(F.split('value', '[ %s]' % punctuation).alias('word'))\n",
    "df3.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo o ultimo elemento do array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+--------+\n",
      "|word                                                                                      |endword |\n",
      "+------------------------------------------------------------------------------------------+--------+\n",
      "|[project, gutenberg, s, the, adventures, of, sherlock, holmes, , by, arthur, conan, doyle]|doyle   |\n",
      "|[this, ebook, is, for, the, use, of, anyone, anywhere, at, no, cost, and, with]           |with    |\n",
      "|[almost, no, restrictions, whatsoever, , , you, may, copy, it, , give, it, away, or]      |or      |\n",
      "|[re-use, it, under, the, terms, of, the, project, gutenberg, license, included]           |included|\n",
      "|[with, this, ebook, or, online, at, www, gutenberg, net]                                  |net     |\n",
      "+------------------------------------------------------------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df4 = df3.filter('doc <> []').withColumn(\"last\", df3['doc'][-1])\n",
    "#where(F.size('doc') > 0)\n",
    "df4 = df3.withColumn(\"endword\", F.element_at(F.col(\"word\"),-1)).where(F.length('endword') > 0)\n",
    "df4.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo a ultima palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, BooleanType, IntegerType, FloatType, ArrayType\n",
    "\n",
    "# UDF remove a ultima palavra\n",
    "rm_last_word = F.udf(lambda x:\n",
    "                     x[:-1] ,\n",
    "                     ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------+--------+\n",
      "|word                                                                               |endword |\n",
      "+-----------------------------------------------------------------------------------+--------+\n",
      "|[project, gutenberg, s, the, adventures, of, sherlock, holmes, , by, arthur, conan]|doyle   |\n",
      "|[this, ebook, is, for, the, use, of, anyone, anywhere, at, no, cost, and]          |with    |\n",
      "|[almost, no, restrictions, whatsoever, , , you, may, copy, it, , give, it, away]   |or      |\n",
      "|[re-use, it, under, the, terms, of, the, project, gutenberg, license]              |included|\n",
      "|[with, this, ebook, or, online, at, www, gutenberg]                                |net     |\n",
      "+-----------------------------------------------------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df4.withColumn('word', rm_last_word('word'))\n",
    "df4.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando/separando as sentenças cujo a ultima palavra seja she, he, hers, his, her, him e com as que não tem essas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6337 342 5995\n"
     ]
    }
   ],
   "source": [
    "df_true = df4.where(\"endword in ('she', 'he', 'hers', 'his', 'her', 'him','them', 'us', 'they','himself', 'herself', 'we')\")\\\n",
    "            .withColumn('label', F.lit(1))\n",
    "\n",
    "df_false = df4.where(\"endword not in ('she', 'he', 'hers', 'his', 'her', 'him','them', 'us', 'they','himself', 'herself', 'we')\")\\\n",
    "              .withColumn('label', F.lit(0))\n",
    "\n",
    "print(df4.count(), df_true.count(), df_false.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando o postivo com o negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+-------+-----+\n",
      "|word                                                                             |endword|label|\n",
      "+---------------------------------------------------------------------------------+-------+-----+\n",
      "|[to, sherlock, holmes, she, is, always, , the, , woman, , i, have, seldom, heard]|him    |1    |\n",
      "|[were, abhorrent, to, his, cold, , precise, but, admirably, balanced, mind, ]    |he     |1    |\n",
      "|[from, time, to, time, i, heard, some, vague, account, of, his, doings, , of]    |his    |1    |\n",
      "|[keen, desire, to, see, holmes, again, , and, to, know, how, he, was, employing] |his    |1    |\n",
      "|[against, the, blind, , he, was, pacing, the, room, swiftly, , eagerly, , with]  |his    |1    |\n",
      "+---------------------------------------------------------------------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "6337\n"
     ]
    }
   ],
   "source": [
    "df5 = df_true.union(df_false)\n",
    "df5.show(5, False)\n",
    "print(df5.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+-------+-----+\n",
      "|word                                                                                 |endword|label|\n",
      "+-------------------------------------------------------------------------------------+-------+-----+\n",
      "|[, quite, so, , , he, answered, , lighting, a, cigarette, , and, throwing]           |himself|1    |\n",
      "|[, five, attempts, have, been, made, , twice, burglars, in, my, pay, ransacked]      |her    |1    |\n",
      "|[she, will, do, it, , you, do, not, know, her, , but, she, has, a, soul, of, steel, ]|she    |1    |\n",
      "|[, she, will, not, be, able, to, , but, i, hear, the, rumble, of, wheels, , it, is]  |her    |1    |\n",
      "|[the, hurrying, swarm, of, pedestrians, , it, was, difficult, to, realise, as]       |we     |1    |\n",
      "+-------------------------------------------------------------------------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.sample(False, .1, 42).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformando Texto para Formato Vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIVIAL_TOKENS = {'', 'u', 'p', '1', '4', 'r', '7', '0', 'g', 'x', 'n', 'v', '6',\\\n",
    "                  'e', 't', 'm', 'f', 'o', '9', 'z', 'k', '5', 's', 'w', 'b', 'h', \\\n",
    "                  'l', '3', '2', 'c', 'q', 'pp', 'j', '8', 'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, BooleanType, IntegerType, FloatType, ArrayType\n",
    "\n",
    "# UDF removes items in TRIVIAL_TOKENS from array\n",
    "rm_trivial_udf = F.udf(lambda x:\n",
    "                     list(set(x) - TRIVIAL_TOKENS) if x\n",
    "                     else x,\n",
    "                     ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+-------+-----+---------------------------------------------------------------------------+\n",
      "|word                                                                             |endword|label|in                                                                         |\n",
      "+---------------------------------------------------------------------------------+-------+-----+---------------------------------------------------------------------------+\n",
      "|[to, sherlock, holmes, she, is, always, , the, , woman, , i, have, seldom, heard]|him    |1    |[woman, holmes, i, to, is, seldom, always, sherlock, the, she, have, heard]|\n",
      "|[were, abhorrent, to, his, cold, , precise, but, admirably, balanced, mind, ]    |he     |1    |[cold, admirably, his, abhorrent, to, but, precise, balanced, mind, were]  |\n",
      "|[from, time, to, time, i, heard, some, vague, account, of, his, doings, , of]    |his    |1    |[his, account, i, time, vague, to, doings, of, from, heard, some]          |\n",
      "+---------------------------------------------------------------------------------+-------+-----+---------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = df5.withColumn('in', rm_trivial_udf('word'))\n",
    "df6.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo 1 - Criando Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer (inputCol = 'word', outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "|                word|endword|label|                  in|            features|\n",
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "|[to, sherlock, ho...|    him|    1|[woman, holmes, i...|(7424,[0,1,3,5,14...|\n",
      "|[were, abhorrent,...|     he|    1|[cold, admirably,...|(7424,[0,5,13,23,...|\n",
      "|[from, time, to, ...|    his|    1|[his, account, i,...|(7424,[0,3,4,5,13...|\n",
      "|[keen, desire, to...|    his|    1|[again, was, he, ...|(7424,[0,2,5,10,1...|\n",
      "|[against, the, bl...|    his|    1|[pacing, room, wa...|(7424,[0,1,10,11,...|\n",
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = cv.fit(df6)\n",
    "df7 = model.transform(df6)\n",
    "df7.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+\n",
      "|                word|endword|label|            features|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "|[to, sherlock, ho...|    him|    1|(7424,[0,1,3,5,14...|\n",
      "|[were, abhorrent,...|     he|    1|(7424,[0,5,13,23,...|\n",
      "|[from, time, to, ...|    his|    1|(7424,[0,3,4,5,13...|\n",
      "|[keen, desire, to...|    his|    1|(7424,[0,2,5,10,1...|\n",
      "|[against, the, bl...|    his|    1|(7424,[0,1,10,11,...|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8 = model.transform(df5.withColumnRenamed('in', 'words'))\\\n",
    "        .withColumnRenamed('words', 'in')\\\n",
    "        .withColumnRenamed('vec', 'invec')\n",
    "df8.drop('sentence').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split para base de treino e base de teste\n",
    "70% do dataset para a base de treino e 30% para a base de teste, com seed de 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4434 1903\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df8.randomSplit((.70, .30), 42)\n",
    "print(df_train.count(), df_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento usado Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numero de iteracoes de treinamento é 100.\n",
    "\n",
    "Os parametros regParam e elasticNetParam são associados a regularização liquida elastica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(maxIter=100, regParam =0.4, elasticNetParam = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do modelo usando a funcao fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_6502c330ea17, numClasses = 2, numFeatures = 7424"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trained = logistic.fit(df_train)\n",
    "df_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations:  18\n"
     ]
    }
   ],
   "source": [
    "print(\"Training iterations: \", df_trained.summary.totalIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando um modelo para avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|                word|endword|label|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|[, and, the, lady...|    his|    1|(7424,[0,1,2,3,14...|[3.23825423668798...|[0.96224874387154...|       0.0|\n",
      "|[, but, this, mai...|    her|    1|(7424,[0,3,5,7,19...|[2.87586248878459...|[0.94664025343764...|       0.0|\n",
      "|[, colonel, lysan...|     he|    1|(7424,[0,6,20,21,...|[3.50581086098324...|[0.97085265437349...|       0.0|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = df_trained.transform(df_test)\n",
    "predicted.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'and', 'the', 'lady', '', 'i', 'fancy', '', 'is', 'miss', 'stoner', '', '', 'observed', 'holmes', '', 'shading']\n",
      "endword : his\n",
      "label : 1\n",
      "features : (7424,[0,1,2,3,14,33,166,175,453,530,613,6669],[6.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [3.238254236687987,-3.238254236687987]\n",
      "probability : [0.9622487438715439,0.037751256128456055]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'but', 'this', 'maid', '', 'alice', '', 'as', 'i', 'understand', '', 'deposes', 'that', 'she', 'went', 'to']\n",
      "endword : her\n",
      "label : 1\n",
      "features : (7424,[0,3,5,7,19,23,29,35,201,275,660,921,4786],[4.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [2.8758624887845974,-2.8758624887845974]\n",
      "probability : [0.9466402534376451,0.053359746562354905]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'colonel', 'lysander', 'stark', 'stopped', 'at', 'last', 'before', 'a', 'low', 'door', '', 'which']\n",
      "endword : he\n",
      "label : 1\n",
      "features : (7424,[0,6,20,21,87,95,129,382,632,1117,1428,1563],[2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [3.505810860983244,-3.505810860983244]\n",
      "probability : [0.9708526543734995,0.0291473456265005]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'i', 'want', 'to', 'test', 'a', 'little', 'theory', 'of', 'mine', '', '', 'said', 'he', '', 'pulling', 'on']\n",
      "endword : his\n",
      "label : 1\n",
      "features : (7424,[0,3,4,5,6,11,31,42,65,523,626,1205,1650,2152],[4.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [2.990909355864684,-2.990909355864684]\n",
      "probability : [0.9521617481210352,0.047838251878964844]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'it', 'is', 'fear', '', 'mr', '', 'holmes', '', 'it', 'is', 'terror', '', '', 'she', 'raised', 'her', 'veil', 'as']\n",
      "endword : she\n",
      "label : 1\n",
      "features : (7424,[0,9,14,19,33,35,36,63,405,835,1130,1614],[6.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [2.8292125304594635,-2.8292125304594635]\n",
      "probability : [0.9442341515629675,0.05576584843703254]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'precisely', '', 'and', 'if', 'it', 'were', 'guilty', '', 'why', 'did', 'he', 'not', 'invent', 'a', 'lie', '']\n",
      "endword : his\n",
      "label : 1\n",
      "features : (7424,[0,2,6,9,11,24,44,54,100,222,923,1945,3443,5131],[4.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [3.415697854392538,-3.415697854392538]\n",
      "probability : [0.9681915463727386,0.03180845362726129]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'quite', 'so', '', '', 'he', 'answered', '', 'lighting', 'a', 'cigarette', '', 'and', 'throwing']\n",
      "endword : himself\n",
      "label : 1\n",
      "features : (7424,[0,2,6,11,34,132,227,753,2542,3288],[5.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [2.9686368330991155,-2.9686368330991155]\n",
      "probability : [0.9511369621646665,0.04886303783533357]\n",
      "prediction : 0.0\n",
      "\n",
      "INCORRECT ==> \n",
      "word : ['', 'see', 'here', '', 'sir', '', 'see', 'what', 'my', 'wife', 'found', 'in', 'its', 'crop', '', '', 'he', 'held', 'out']\n",
      "endword : his\n",
      "label : 1\n",
      "features : (7424,[0,8,11,15,49,58,71,107,109,120,174,213,359,1160],[5.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
      "rawPrediction : [2.935047051237188,-2.935047051237188]\n",
      "probability : [0.9495519932754243,0.05044800672457573]\n",
      "prediction : 0.0\n"
     ]
    }
   ],
   "source": [
    "for x in predicted.take(8):\n",
    "    print()\n",
    "    if x.label != int(x.prediction):\n",
    "        print(\"INCORRECT ==> \")\n",
    "    for y in predicted.schema.names:\n",
    "        print(y,\":\", x[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c7956a840118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Right\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"Wrong\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "x = predicted.first\n",
    "print(\"Right\" if x.label == int(x.prediction) else \"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.first of DataFrame[word: array<string>, endword: string, label: int, features: vector, rawPrediction: vector, probability: vector, prediction: double]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a acuracia da classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionSummary at 0x22cb82c0f48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = df_trained.evaluate(df_test)\n",
    "model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurracy: 0.536431\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAcurracy: %2f\" % model_stats.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
