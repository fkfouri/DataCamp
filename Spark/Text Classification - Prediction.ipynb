{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "Este fará usando conceitos de Machine Learning uma previsão da última palavra de uma frase/setença de uma pessoa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-Y520:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Endword Prediction  - Fabio Kfouri</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e9f778a208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Spark Endword Prediction  - Fabio Kfouri\")\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Project Gutenberg...|\n",
      "|                    |\n",
      "|This eBook is for...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read book\n",
    "df = spark.read.text(\"sherlock\\sherlock.txt\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+\n",
      "|word                                                                                      |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "|[project, gutenberg, s, the, adventures, of, sherlock, holmes, , by, arthur, conan, doyle]|\n",
      "|[]                                                                                        |\n",
      "|[this, ebook, is, for, the, use, of, anyone, anywhere, at, no, cost, and, with]           |\n",
      "|[almost, no, restrictions, whatsoever, , , you, may, copy, it, , give, it, away, or]      |\n",
      "|[re-use, it, under, the, terms, of, the, project, gutenberg, license, included]           |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformando em minuscula\n",
    "df1 = df.select(F.lower(F.col('value')).alias('value'))\n",
    "# Replace de termos\n",
    "df2 = df1.select(F.regexp_replace('value', 'mr\\.', 'mr').alias('value'))\n",
    "df2 = df1.select(F.regexp_replace('value', 'don\\'t', 'do not').alias('value'))\n",
    "# Tokenizando e removendo simbolos indesejados\n",
    "punctuation = \"_|.\\?\\!\\\",\\'\\[\\]\\*():;<>”“’\"\n",
    "df3 = df2.select(F.split('value', '[ %s]' % punctuation).alias('word'))\n",
    "df3.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo o ultimo elemento do array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+--------+\n",
      "|word                                                                                      |endword |\n",
      "+------------------------------------------------------------------------------------------+--------+\n",
      "|[project, gutenberg, s, the, adventures, of, sherlock, holmes, , by, arthur, conan, doyle]|doyle   |\n",
      "|[this, ebook, is, for, the, use, of, anyone, anywhere, at, no, cost, and, with]           |with    |\n",
      "|[almost, no, restrictions, whatsoever, , , you, may, copy, it, , give, it, away, or]      |or      |\n",
      "|[re-use, it, under, the, terms, of, the, project, gutenberg, license, included]           |included|\n",
      "|[with, this, ebook, or, online, at, www, gutenberg, net]                                  |net     |\n",
      "+------------------------------------------------------------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df4 = df3.filter('doc <> []').withColumn(\"last\", df3['doc'][-1])\n",
    "#where(F.size('doc') > 0)\n",
    "df4 = df3.withColumn(\"endword\", F.element_at(F.col(\"word\"),-1)).where(F.length('endword') > 0)\n",
    "df4.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando/separando as sentenças cujo a ultima palavra seja she, he, hers, his, her, him e com as que não tem essas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6337 266 6071\n"
     ]
    }
   ],
   "source": [
    "df_true = df4.where(\"endword in ('she', 'he', 'hers', 'his', 'her', 'him')\")\\\n",
    "            .withColumn('label', F.lit(1))\n",
    "\n",
    "df_false = df4.where(\"endword not in ('she', 'he', 'hers', 'his', 'her', 'him')\")\\\n",
    "              .withColumn('label', F.lit(0))\n",
    "\n",
    "print(df4.count(), df_true.count(), df_false.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando o postivo com o negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+-------+-----+\n",
      "|word                                                                                  |endword|label|\n",
      "+--------------------------------------------------------------------------------------+-------+-----+\n",
      "|[to, sherlock, holmes, she, is, always, , the, , woman, , i, have, seldom, heard, him]|him    |1    |\n",
      "|[were, abhorrent, to, his, cold, , precise, but, admirably, balanced, mind, , he]     |he     |1    |\n",
      "|[from, time, to, time, i, heard, some, vague, account, of, his, doings, , of, his]    |his    |1    |\n",
      "|[keen, desire, to, see, holmes, again, , and, to, know, how, he, was, employing, his] |his    |1    |\n",
      "|[against, the, blind, , he, was, pacing, the, room, swiftly, , eagerly, , with, his]  |his    |1    |\n",
      "+--------------------------------------------------------------------------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "6337\n"
     ]
    }
   ],
   "source": [
    "df5 = df_true.union(df_false)\n",
    "df5.show(5, False)\n",
    "print(df5.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+-------+-----+\n",
      "|word                                                                                    |endword|label|\n",
      "+----------------------------------------------------------------------------------------+-------+-----+\n",
      "|[writes, upon, bohemian, paper, and, prefers, wearing, a, mask, to, showing, his]       |his    |1    |\n",
      "|[, there, are, three, hundred, pounds, in, gold, and, seven, hundred, in, notes, , , he]|he     |1    |\n",
      "|[investigation, which, my, friend, had, on, hand, , there, was, something, in, his]     |his    |1    |\n",
      "|[she, half, drew, it, out, , when, i, cried, out, that, it, was, a, false, alarm, , she]|she    |1    |\n",
      "|[an, absolute, imbecile, in, his, profession, , he, has, one, positive, virtue, , he]   |he     |1    |\n",
      "+----------------------------------------------------------------------------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.sample(False, .1, 42).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformando Texto para Formato Vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIVIAL_TOKENS = {'', 'u', 'p', '1', '4', 'r', '7', '0', 'g', 'x', 'n', 'v', '6',\\\n",
    "                  'e', 't', 'm', 'f', 'o', '9', 'z', 'k', '5', 's', 'w', 'b', 'h', \\\n",
    "                  'l', '3', '2', 'c', 'q', 'pp', 'j', '8', 'y'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, BooleanType, IntegerType, FloatType, ArrayType\n",
    "\n",
    "# UDF removes items in TRIVIAL_TOKENS from array\n",
    "rm_trivial_udf = F.udf(lambda x:\n",
    "                     list(set(x) - TRIVIAL_TOKENS) if x\n",
    "                     else x,\n",
    "                     ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+\n",
      "|                word|endword|label|                  in|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "|[to, sherlock, ho...|    him|    1|[woman, holmes, i...|\n",
      "|[were, abhorrent,...|     he|    1|[cold, admirably,...|\n",
      "|[from, time, to, ...|    his|    1|[his, account, i,...|\n",
      "|[keen, desire, to...|    his|    1|[again, was, his,...|\n",
      "|[against, the, bl...|    his|    1|[pacing, room, wa...|\n",
      "|[i, could, not, h...|    his|    1|[which, at, his, ...|\n",
      "|[writes, upon, bo...|    his|    1|[writes, his, wea...|\n",
      "|[barbaric, opulen...|     he|    1|[by, which, was, ...|\n",
      "|[, five, attempts...|    her|    1|[ransacked, twice...|\n",
      "|[she, will, do, i...|    she|    1|[it, soul, a, not...|\n",
      "|[, there, are, th...|     he|    1|[notes, gold, he,...|\n",
      "|[investigation, w...|    his|    1|[something, which...|\n",
      "|[times, before, i...|     he|    1|[certain, was, in...|\n",
      "|[tweed-suited, an...|    his|    1|[of, his, old, as...|\n",
      "|[, well, , really...|     he|    1|[really, laughed,...|\n",
      "|[character, of, a...|    his|    1|[of, his, clergym...|\n",
      "|[, she, will, not...|    her|    1|[will, i, rumble,...|\n",
      "|[adler, , as, i, ...|    she|    1|[still, will, adl...|\n",
      "|[whether, he, was...|     he|    1|[at, was, seized,...|\n",
      "|[she, half, drew,...|    she|    1|[out, cried, was,...|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = df5.withColumn('in', rm_trivial_udf('word'))\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo 1 - Criando Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer (inputCol = 'word', outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "|                word|endword|label|                  in|            features|\n",
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "|[to, sherlock, ho...|    him|    1|[woman, holmes, i...|(7659,[0,1,3,6,14...|\n",
      "|[were, abhorrent,...|     he|    1|[cold, admirably,...|(7659,[0,6,11,13,...|\n",
      "|[from, time, to, ...|    his|    1|[his, account, i,...|(7659,[0,3,4,6,13...|\n",
      "|[keen, desire, to...|    his|    1|[again, was, his,...|(7659,[0,2,6,10,1...|\n",
      "|[against, the, bl...|    his|    1|[pacing, room, wa...|(7659,[0,1,10,11,...|\n",
      "+--------------------+-------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = cv.fit(df6)\n",
    "df7 = model.transform(df6)\n",
    "df7.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+\n",
      "|                word|endword|label|            features|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "|[to, sherlock, ho...|    him|    1|(7659,[0,1,3,6,14...|\n",
      "|[were, abhorrent,...|     he|    1|(7659,[0,6,11,13,...|\n",
      "|[from, time, to, ...|    his|    1|(7659,[0,3,4,6,13...|\n",
      "|[keen, desire, to...|    his|    1|(7659,[0,2,6,10,1...|\n",
      "|[against, the, bl...|    his|    1|(7659,[0,1,10,11,...|\n",
      "+--------------------+-------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df8 = model.transform(df5.withColumnRenamed('in', 'words'))\\\n",
    "        .withColumnRenamed('words', 'in')\\\n",
    "        .withColumnRenamed('vec', 'invec')\n",
    "df8.drop('sentence').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split para base de treino e base de teste\n",
    "70% do dataset para a base de treino e 30% para a base de teste, com seed de 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4434 1903\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df8.randomSplit((.70, .30), 42)\n",
    "print(df_train.count(), df_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento usado Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numero de iteracoes de treinamento é 100.\n",
    "\n",
    "Os parametros regParam e elasticNetParam são associados a regularização liquida elastica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(maxIter=100, regParam =0.4, elasticNetParam = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do modelo usando a funcao fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_759de081ecf7, numClasses = 2, numFeatures = 7659"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fitted = logistic.fit(df_train)\n",
    "df_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations:  18\n"
     ]
    }
   ],
   "source": [
    "print(\"Training iterations: \", df_fitted.summary.totalIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
